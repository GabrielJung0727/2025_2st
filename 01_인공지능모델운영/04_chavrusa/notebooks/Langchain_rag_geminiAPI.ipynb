{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangChain + Gemini RAG 간단 실습\n",
        "- 문서를 불러와 쪼개고, 임베딩 → FAISS → Retriever → Gemini로 답변을 생성하는 최소 예제\n",
        "- `requirements.txt`를 설치하고 실행하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 필요 시 패키지 설치 (주석 해제해서 사용)\n",
        "# !pip install -r ../requirements.txt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, getpass, textwrap\n",
        "\n",
        "if 'GEMINI_API_KEY' not in os.environ:\n",
        "    os.environ['GEMINI_API_KEY'] = getpass.getpass('Enter GEMINI_API_KEY: ')\n",
        "    print('GEMINI_API_KEY set from prompt')\n",
        "else:\n",
        "    print('GEMINI_API_KEY detected')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# 1) 로컬 문서 적재\n",
        "with open('../data/sample.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "docs = [Document(page_content=text, metadata={'source': 'sample.txt'})]\n",
        "print('Loaded docs:', len(docs))\n",
        "\n",
        "# 2) Chunking\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "splits = splitter.split_documents(docs)\n",
        "print('Chunks:', len(splits))\n",
        "\n",
        "# 3) 임베딩 + VectorStore (FAISS)\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model='models/text-embedding-004')\n",
        "vectorstore = FAISS.from_documents(splits, embedding=embeddings)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={'k': 3})\n",
        "\n",
        "# 4) 프롬프트 + 모델\n",
        "prompt = ChatPromptTemplate.from_template(textwrap.dedent('''\n",
        "    아래는 참고할 문서입니다. 답변 시 문서의 내용을 근거로 해주세요.\n",
        "    ----------------\n",
        "    {context}\n",
        "    ----------------\n",
        "    질문: {question}\n",
        "    답변:'''\n",
        "))\n",
        "model = ChatGoogleGenerativeAI(model='gemini-1.5-flash', temperature=0.3)\n",
        "\n",
        "def format_docs(docs):\n",
        "    return '\n\n'.join(d.page_content for d in docs)\n",
        "\n",
        "rag_chain = ({'context': retriever | format_docs, 'question': RunnablePassthrough()}\n",
        "             | prompt\n",
        "             | model\n",
        "             | StrOutputParser())\n",
        "\n",
        "answer = rag_chain.invoke('카페에서 파는 음료와 운영 시간을 알려줘')\n",
        "print(answer)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}