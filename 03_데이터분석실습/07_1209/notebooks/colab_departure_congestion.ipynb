{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incheon Departure Congestion (Colab)\n",
    "\n",
    "Colab end-to-end: 데이터 수집 -> EDA -> 회귀/잔차 -> LSTM 예측 + 시각화."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn torch requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 환경변수와 키 설정\n",
    "- data.go.kr 서비스키를 URL 인코딩된 상태로 넣어주세요.\n",
    "- Colab에서는 `os.environ[\"INCHEON_API_KEY\"]`에 직접 할당."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import unquote\n",
    "\n",
    "# TODO: 아래에 본인 키 입력 (URL-encoded key)\n",
    "os.environ[\"INCHEON_API_KEY\"] = \"Kgn3NZtSyDOE51%2FjW0cW8kkX7Yxvga%2FZ%2FdrpGvn%2B0m5IBqRV9UCKO%2BXRxFXWwKNHPsRUqzPFW6CdTSHbYln2Kw%3D%3D\"\n",
    "assert os.environ[\"INCHEON_API_KEY\"], \"서비스키를 설정하세요\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터 수집\n",
    "- XML 응답을 파싱해서 DataFrame으로 변환\n",
    "- 옵션: terminalId(`P01`), gateId(`DG2_E`), 페이지/행수 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terminalid</th>\n",
       "      <th>gateid</th>\n",
       "      <th>exitnumber</th>\n",
       "      <th>gatenumber</th>\n",
       "      <th>regdate</th>\n",
       "      <th>congestion</th>\n",
       "      <th>waittime</th>\n",
       "      <th>operatingtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P01</td>\n",
       "      <td>DG1_E</td>\n",
       "      <td>1</td>\n",
       "      <td>DG1_E</td>\n",
       "      <td>2025-12-09 13:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>06:30~09:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P01</td>\n",
       "      <td>DG1_W</td>\n",
       "      <td>1</td>\n",
       "      <td>DG1_W</td>\n",
       "      <td>2025-12-09 13:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>06:30~09:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01</td>\n",
       "      <td>DG2_E</td>\n",
       "      <td>2</td>\n",
       "      <td>DG2_E</td>\n",
       "      <td>2025-12-09 13:50:00</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>06:00~20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P01</td>\n",
       "      <td>DG2_W</td>\n",
       "      <td>2</td>\n",
       "      <td>DG2_W</td>\n",
       "      <td>2025-12-09 13:50:00</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>06:00~20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P01</td>\n",
       "      <td>DG3_E</td>\n",
       "      <td>3</td>\n",
       "      <td>DG3_E</td>\n",
       "      <td>2025-12-09 13:50:00</td>\n",
       "      <td>76</td>\n",
       "      <td>17</td>\n",
       "      <td>00:00~24:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  terminalid gateid exitnumber gatenumber             regdate  congestion  \\\n",
       "0        P01  DG1_E          1      DG1_E 2025-12-09 13:50:00           0   \n",
       "1        P01  DG1_W          1      DG1_W 2025-12-09 13:50:00           0   \n",
       "2        P01  DG2_E          2      DG2_E 2025-12-09 13:50:00          16   \n",
       "3        P01  DG2_W          2      DG2_W 2025-12-09 13:50:00          19   \n",
       "4        P01  DG3_E          3      DG3_E 2025-12-09 13:50:00          76   \n",
       "\n",
       "   waittime operatingtime  \n",
       "0         6   06:30~09:30  \n",
       "1         6   06:30~09:30  \n",
       "2         8   06:00~20:00  \n",
       "3         8   06:00~20:00  \n",
       "4        17   00:00~24:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "BASE_URL = \"https://apis.data.go.kr/B551177/statusOfDepartureCongestion/getDepartureCongestion\"\n",
    "\n",
    "def parse_xml_items(text: str) -> List[Dict]:\n",
    "    root = ET.fromstring(text)\n",
    "    items_el = root.find(\".//items\")\n",
    "    if items_el is None:\n",
    "        return []\n",
    "    items = []\n",
    "    for item_el in items_el.findall(\"item\"):\n",
    "        items.append({child.tag: child.text for child in item_el})\n",
    "    return items\n",
    "\n",
    "def normalize_item(item: Dict) -> Dict:\n",
    "    gate_id = item.get(\"gateId\", \"\") or \"\"\n",
    "    exitnumber = \"\"\n",
    "    if gate_id:\n",
    "        for part in gate_id.split(\"_\"):\n",
    "            if part.startswith(\"DG\") and part[2:].isdigit():\n",
    "                exitnumber = part[2:]\n",
    "    return {\n",
    "        \"terminalid\": (item.get(\"terminalId\", \"\") or \"\").upper(),\n",
    "        \"gateid\": gate_id.upper(),\n",
    "        \"exitnumber\": exitnumber,\n",
    "        \"gatenumber\": gate_id.upper(),\n",
    "        \"regdate\": item.get(\"occurtime\", \"\"),\n",
    "        \"congestion\": item.get(\"waitLength\", \"\"),\n",
    "        \"waittime\": item.get(\"waitTime\", \"\"),\n",
    "        \"operatingtime\": item.get(\"operatingTime\", \"\"),\n",
    "    }\n",
    "\n",
    "def fetch_page(page: int = 1, rows: int = 200, terminal_id: str | None = None, gate_id: str | None = None) -> List[Dict]:\n",
    "    raw_key = os.getenv(\"INCHEON_API_KEY\")\n",
    "    assert raw_key, \"환경변수 INCHEON_API_KEY가 필요합니다\"\n",
    "    key = unquote(raw_key)\n",
    "    params = {\n",
    "        \"serviceKey\": key,\n",
    "        \"pageNo\": page,\n",
    "        \"numOfRows\": rows,\n",
    "        \"type\": \"xml\",\n",
    "    }\n",
    "    if terminal_id:\n",
    "        params[\"terminalId\"] = terminal_id\n",
    "    if gate_id:\n",
    "        params[\"gateId\"] = gate_id\n",
    "    resp = requests.get(BASE_URL, params=params, timeout=15)\n",
    "    resp.raise_for_status()\n",
    "    items = parse_xml_items(resp.text)\n",
    "    return [normalize_item(it) for it in items]\n",
    "\n",
    "def fetch_all(pages: int = 3, rows: int = 200, terminal_id: str | None = None, gate_id: str | None = None) -> pd.DataFrame:\n",
    "    all_rows = []\n",
    "    for p in range(1, pages + 1):\n",
    "        page_rows = fetch_page(p, rows, terminal_id, gate_id)\n",
    "        if not page_rows:\n",
    "            break\n",
    "        all_rows.extend(page_rows)\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    df[\"regdate\"] = pd.to_datetime(df[\"regdate\"], format=\"%Y%m%d%H%M%S\", errors=\"coerce\")\n",
    "    df[\"congestion\"] = pd.to_numeric(df[\"congestion\"], errors=\"coerce\")\n",
    "    df[\"waittime\"] = pd.to_numeric(df[\"waittime\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"regdate\", \"congestion\"])\n",
    "    df = df.sort_values(\"regdate\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df = fetch_all(pages=5, rows=200, terminal_id=None, gate_id=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) EDA: 시계열/막대/분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.lineplot(data=df, x=\"regdate\", y=\"congestion\", hue=\"terminalid\")\n",
    "plt.title(\"Congestion over time (by terminal)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(data=df, x=\"gateid\", y=\"congestion\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Congestion by gate\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df[\"congestion\"], kde=True)\n",
    "plt.title(\"Distribution of congestion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 회귀 + 잔차\n",
    "- 원-핫 인코딩: terminal/gate/exit\n",
    "- 시간 특성: hour/dow sin-cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "df_feat = df.copy()\n",
    "df_feat[\"hour\"] = df_feat[\"regdate\"].dt.hour\n",
    "df_feat[\"dow\"] = df_feat[\"regdate\"].dt.dayofweek\n",
    "df_feat[\"hour_sin\"] = np.sin(2*np.pi*df_feat[\"hour\"]/24)\n",
    "df_feat[\"hour_cos\"] = np.cos(2*np.pi*df_feat[\"hour\"]/24)\n",
    "df_feat[\"dow_sin\"] = np.sin(2*np.pi*df_feat[\"dow\"]/7)\n",
    "df_feat[\"dow_cos\"] = np.cos(2*np.pi*df_feat[\"dow\"]/7)\n",
    "\n",
    "target = df_feat[\"congestion\"]\n",
    "feature_cols = [\"terminalid\", \"gateid\", \"exitnumber\", \"hour_sin\", \"hour_cos\", \"dow_sin\", \"dow_cos\"]\n",
    "X = df_feat[feature_cols]\n",
    "\n",
    "cat_cols = [\"terminalid\", \"gateid\", \"exitnumber\"]\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "])\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"prep\", pre),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "print({\"rmse\": rmse, \"mae\": mae})\n",
    "\n",
    "residuals = y_test - preds\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Residual distribution (linear regression)\")\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(x=preds, y=y_test)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Pred vs Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) LSTM 예측 (시계열)\n",
    "- lookback 분 단위로 시퀀스 구성\n",
    "- train/val 손실 곡선 출력\n",
    "- 마지막 시퀀스로 n 스텝 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List\n",
    "\n",
    "@dataclass\n",
    "class LSTMConfig:\n",
    "    lookback: int = 30\n",
    "    hidden_size: int = 64\n",
    "    num_layers: int = 2\n",
    "    lr: float = 1e-3\n",
    "    epochs: int = 20\n",
    "    train_split: float = 0.8\n",
    "    device: str = \"cpu\"\n",
    "\n",
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, n_features: int, config: LSTMConfig):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(n_features, config.hidden_size, num_layers=config.num_layers, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config.hidden_size, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last = out[:, -1, :]\n",
    "        return self.head(last)\n",
    "\n",
    "def make_sequences(df_in: pd.DataFrame, config: LSTMConfig):\n",
    "    feat_cols = [\"congestion\", \"hour_sin\", \"hour_cos\", \"dow_sin\", \"dow_cos\"]\n",
    "    df_seq = df_in.copy()\n",
    "    df_seq[\"hour\"] = df_seq[\"regdate\"].dt.hour\n",
    "    df_seq[\"dow\"] = df_seq[\"regdate\"].dt.dayofweek\n",
    "    df_seq[\"hour_sin\"] = np.sin(2*np.pi*df_seq[\"hour\"]/24)\n",
    "    df_seq[\"hour_cos\"] = np.cos(2*np.pi*df_seq[\"hour\"]/24)\n",
    "    df_seq[\"dow_sin\"] = np.sin(2*np.pi*df_seq[\"dow\"]/7)\n",
    "    df_seq[\"dow_cos\"] = np.cos(2*np.pi*df_seq[\"dow\"]/7)\n",
    "    values = df_seq[feat_cols].dropna().to_numpy()\n",
    "    seqs, tgts = [], []\n",
    "    for i in range(len(values) - config.lookback):\n",
    "        seqs.append(values[i:i+config.lookback])\n",
    "        tgts.append(values[i+config.lookback, 0])\n",
    "    X = torch.tensor(np.stack(seqs), dtype=torch.float32)\n",
    "    y = torch.tensor(tgts, dtype=torch.float32).unsqueeze(-1)\n",
    "    return X, y\n",
    "\n",
    "def train_lstm(df_in: pd.DataFrame, config: LSTMConfig):\n",
    "    X, y = make_sequences(df_in, config)\n",
    "    split = int(len(X) * config.train_split)\n",
    "    X_tr, X_val = X[:split], X[split:]\n",
    "    y_tr, y_val = y[:split], y[split:]\n",
    "\n",
    "    model = LSTMForecaster(X.shape[2], config).to(config.device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    train_loss, val_loss = [], []\n",
    "    for ep in range(config.epochs):\n",
    "        model.train(); opt.zero_grad()\n",
    "        pred = model(X_tr)\n",
    "        loss = loss_fn(pred, y_tr)\n",
    "        loss.backward(); opt.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            v_pred = model(X_val)\n",
    "            v_loss = loss_fn(v_pred, y_val)\n",
    "        train_loss.append(loss.item()); val_loss.append(v_loss.item())\n",
    "        print(f\"Epoch {ep+1}/{config.epochs} train={loss.item():.4f} val={v_loss.item():.4f}\")\n",
    "    return model, train_loss, val_loss, X, y\n",
    "\n",
    "config = LSTMConfig(lookback=30, epochs=15, device=\"cpu\")\n",
    "model, tr_loss, val_loss, X_all, y_all = train_lstm(df, config)\n",
    "\n",
    "plt.plot(tr_loss, label=\"train\")\n",
    "plt.plot(val_loss, label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"LSTM loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 최근 구간으로 n-step 예측\n",
    "n_steps = 20\n",
    "last_seq = X_all[-1:].clone()\n",
    "future = []\n",
    "model.eval()\n",
    "for _ in range(n_steps):\n",
    "    with torch.no_grad():\n",
    "        pred = model(last_seq)\n",
    "    future.append(pred.item())\n",
    "    # shift window: drop first, append predicted congestion with same temporal encodings (keep last encodings)\n",
    "    new_row = last_seq[0, -1, :].clone()\n",
    "    new_row[0] = pred.item()\n",
    "    last_seq = torch.cat([last_seq[:, 1:, :], new_row.view(1,1,-1)], dim=1)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(range(len(y_all[-100:])), y_all[-100:].numpy(), label=\"actual\")\n",
    "plt.plot(range(len(y_all[-1:]), len(y_all[-1:])+n_steps), future, label=\"forecast\")\n",
    "plt.title(\"Recent actual vs forecast\")\n",
    "plt.legend(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
